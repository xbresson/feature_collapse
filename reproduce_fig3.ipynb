{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS FOR DATA MODEL    \n",
    "nc = 3 \n",
    "nw = 1200 \n",
    "L = 15 \n",
    "K = 1000 \n",
    "word_freq = 'uniform'\n",
    "\n",
    "# PARAMETERS FOR NEURAL NETWORK ARCHITECTURE\n",
    "layer_norm = False\n",
    "d = 100 \n",
    "\n",
    "# PARAMETERS FOR TRAINING\n",
    "nspl = 5\n",
    "weight_decay_W = 0.001   \n",
    "weight_decay_U = 0.001 \n",
    "lr = 0.1 \n",
    "bsz = 100 \n",
    "num_epochs = 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModel:\n",
    "    \n",
    "    def __init__(self, nc, nw, L, K, word_freq = 'uniform'):\n",
    "        \"\"\"\n",
    "        INPUT: nc, nw, L and K are the number of concepts, the number of words, the length\n",
    "               of the sentences, and the number of classes, respectively. \n",
    "               word_freq must be be either 'uniform' or 'zipf'\n",
    "        \n",
    "        ATTRIBUTES: Z is a LongTensor of shape (K,L) that contains the K latent variables. That is:\n",
    "                                  Z[k] = k-th latent variable\n",
    "                    These K latent variables are selected uniformly at random in the latent space.\n",
    "                    \n",
    "                    mu is a FloatTensor of shape (sc,) that contains the word frequencies. That is:\n",
    "                                  mu[beta] = frequency of word beta-th word of each concept\n",
    "        \"\"\"\n",
    "        \n",
    "        # select the latent variables uniformly at random in the latent space\n",
    "        self.Z = torch.randint(0, nc, size=(K,L) )\n",
    "    \n",
    "        # Define word frequencies mu_1, ... mu_sc (either uniform or Zipf distribution)\n",
    "        sc = nw // nc\n",
    "        if word_freq == 'zipf': \n",
    "            ii = torch.arange(1,sc+1)\n",
    "            mu = 1 / ii\n",
    "            mu = mu / mu.sum()\n",
    "        elif word_freq == 'uniform':\n",
    "            mu = 1/sc * torch.ones(sc)\n",
    "            \n",
    "        self.L = L    \n",
    "        self.K = K\n",
    "        self.mu = mu\n",
    "        \n",
    "    def sample(self,nspl):\n",
    "        \"\"\"\n",
    "        Generate N = K*nspl sentences \n",
    "        Each latent variable generate nspl sentences\n",
    "        Sentences generated by the k-th latent variable are assigned label k\n",
    "        \n",
    "        OUTPUT:\n",
    "        Alpha: LongTensor of shape (N,L) whose entries belong to {0,1,...,nc-1}\n",
    "        Beta: Longtensor of shape (N,L) whose entries belong to {0,1,...,sc-1}\n",
    "        label:  Longtensor of shape (N,) whose entries belong to {0,1,...,K}  \n",
    "        \n",
    "        \n",
    "        Recall that a sentence is a sequence of L words, and that it takes the form\n",
    "        \n",
    "        x = [(alpha_1,beta_1) , (alpha_2,beta_2) , ... , (alpha_L,beta_L)]\n",
    "        \n",
    "        This functions generates N = K*nspl sentences. Its outputs are:\n",
    "        \n",
    "        \n",
    "        The i-th data points is:\n",
    "        \n",
    "        [ (Alpha[i,1] , Beta[i,1]) , (Alpha[i,2] , Beta[i,2])  , ... , (Alpha[i,L] , Beta[i,L]) ]\n",
    "        \n",
    "        and it has label label[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        distribution = torch.distributions.categorical.Categorical(self.mu)\n",
    "        \n",
    "        Alpha = self.Z.repeat_interleave(nspl,dim=0)\n",
    "        Beta =  distribution.sample( sample_shape = ( self.K*nspl , self.L)  )\n",
    "        labels =  torch.arange(K).repeat_interleave(nspl,dim=0) \n",
    "        \n",
    "        return Alpha, Beta, labels       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodel = DataModel(nc, nw, L, K, word_freq)\n",
    "Alpha, Beta, label = datamodel.sample(nspl) #create the training set\n",
    "test_Alpha, test_Beta, test_label = datamodel.sample(5) #create the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the tuple $(\\alpha,\\beta)$ denote the $\\beta$-th word of the $\\alpha$-th concept. It  has a probability $\\mu_\\beta$ of being sampled. \n",
    "\n",
    "### Each latent variable is a sequence of $L$ concept\n",
    "### $$\n",
    "{\\bf z} = [\\alpha_1, \\alpha_2, \\ldots, \\alpha_L] \\qquad \\text{where } \\alpha_\\ell \\in [n_c]\n",
    "$$\n",
    "### and it generates data points of the form\n",
    "### $${\\bf x} = [\\;(\\alpha_1,\\beta_1),\\; (\\alpha_2, \\beta_2),\\, \\ldots,\\; (\\alpha_L,\\beta_L)\\;]  \\qquad \\text{where } \\alpha_\\ell \\in [n_c] \\text{ and } \\beta_\\ell \\in [s_c] \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the first latent variable (we have nc=3 concepts and L=15):\n",
      "\n",
      "tensor([2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 1, 1])\n",
      "\n",
      "Here is one sentence from the training set that was generated by the above latent variable\n",
      "(each of the 3 concepts contains 400 words)\n",
      "\n",
      "[(2, 308), (2, 272), (1, 130), (0, 381), (2, 289), (1, 91), (0, 255), (0, 249), (1, 289), (2, 241), (1, 243), (0, 115), (1, 250), (1, 388), (1, 378)]\n",
      "\n",
      "Here is another one:\n",
      "\n",
      "[(2, 251), (2, 177), (1, 251), (0, 287), (2, 54), (1, 91), (0, 118), (0, 159), (1, 222), (2, 207), (1, 376), (0, 245), (1, 6), (1, 323), (1, 278)]\n",
      "\n",
      "Finally, here is a plot of the word frequencies mu_beta:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Here is the first latent variable (we have nc=3 concepts and L=15):\\n')\n",
    "print(datamodel.Z[0])\n",
    "\n",
    "print('\\nHere is one sentence from the training set that was generated by the above latent variable')\n",
    "print('(each of the 3 concepts contains 400 words)\\n')\n",
    "print(  [ (Alpha[0,ell].item(), Beta[0,ell].item()) for ell in range(L) ] )\n",
    "\n",
    "print('\\nHere is another one:\\n')\n",
    "print(  [ (Alpha[1,ell].item(), Beta[1,ell].item()) for ell in range(L) ] )\n",
    "\n",
    "print('\\nFinally, here is a plot of the word frequencies mu_beta:\\n')\n",
    "plt.plot(datamodel.mu,'o')\n",
    "plt.title('word frequencies')\n",
    "plt.xlabel('beta')\n",
    "plt.ylabel('mu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding of the words\n",
    "### Each word has the format $(\\alpha,\\beta)$ where $0 \\le \\alpha \\le n_c-1$ and $0 \\le \\beta \\le s_c-1$. In order to use the pytorch embedding module, we need to replace this double index by a single index. So we simply do\n",
    "### $$(\\alpha,\\beta) \\mapsto  \\alpha s_c + \\beta $$ \n",
    "### We then put the train set into a tensor train_data of shape $(N , L)$ and with entries in $\\{0,1, \\ldots , n_w-1\\}$, where $N=Kn_{spl}$ is the total number of training points.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = nw // nc\n",
    "train_data = sc*Alpha + Beta\n",
    "train_label = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = sc * test_Alpha + test_Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, nw, L, d, K, layer_norm=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb  = nn.Embedding(nw,d)\n",
    "        if layer_norm:\n",
    "            self.lnorm = nn.LayerNorm(d, elementwise_affine=False)\n",
    "        self.clf  = nn.Linear(L*d, K, bias=False) \n",
    "        \n",
    "        # Initializing the weights to be close to zero makes the training easier  \n",
    "        self.emb.weight.data = self.emb.weight.data / 1000\n",
    "        self.clf.weight.data = self.clf.weight.data / 1000\n",
    "        \n",
    "        self.L = L\n",
    "        self.d = d\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #(bsz, L) -->(bsz, L, d) \n",
    "        x = self.emb(x)\n",
    "        \n",
    "        if layer_norm:\n",
    "            x = self.lnorm(x) \n",
    "        \n",
    "        #(bsz, L, d) -->  (bsz, L*d)\n",
    "        x = x.view(-1, self.L*self.d)\n",
    "        \n",
    "        # (bsz, L*d) --> (bsz, K)\n",
    "        x = self.clf(x)\n",
    "        \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNet( nw=nw , L=L, d=d, K=K, layer_norm = layer_norm  )\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "                        {'params': net.emb.parameters(),  'weight_decay': weight_decay_W},\n",
    "                        {'params': net.clf.parameters() , 'weight_decay': weight_decay_U}\n",
    "                            ] , lr=lr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error( scores , labels ):\n",
    "    bsz = scores.shape[0]\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches = indicator.sum()\n",
    "    return 1-num_matches.float()/bsz   \n",
    "\n",
    "def eval_on_test_set():\n",
    "    test_size = test_data.shape[0]\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, test_size, bsz):\n",
    "            minibatch_data = test_data[i:i+bsz].to(device)\n",
    "            minibatch_label= test_label[i:i+bsz].to(device)\n",
    "            scores = net( minibatch_data ) \n",
    "            error = get_error( scores , minibatch_label)\n",
    "            running_error += error.item()\n",
    "            num_batches+=1\n",
    "    return running_error/num_batches            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1200 \t  train loss: 6.908e+00 \t  train accuracy: 0.1% \t test accuracy: 0.1%\n"
     ]
    }
   ],
   "source": [
    "train_size = train_data.shape[0]\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "\n",
    "    shuffled_indices = torch.randperm(train_size)\n",
    "    running_loss = 0\n",
    "    running_error = 0\n",
    "    num_batches_this_epoch = 0\n",
    "\n",
    "    for count in range(0,train_size,bsz):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bsz]\n",
    "        minibatch_data =  train_data[indices].to(device) \n",
    "        minibatch_label= train_label[indices].to(device)\n",
    "        scores = net( minibatch_data) \n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        num_batches_this_epoch += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_loss += loss.item()\n",
    "            error = get_error( scores , minibatch_label)\n",
    "            running_error += error.item() \n",
    "\n",
    "    train_loss = running_loss/num_batches_this_epoch\n",
    "    train_error = running_error/num_batches_this_epoch\n",
    "    \n",
    "    if epoch == 1  or  epoch % 100 == 0:    \n",
    "        test_error = eval_on_test_set()\n",
    "        print( 'epoch {}/{} \\t  train loss: {:.3e} \\t  train accuracy: {:.1f}% \\t test accuracy: {:.1f}%'.format( \n",
    "        epoch, num_epochs, train_loss, (1-train_error)*100, (1-test_error)*100 ) )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D visualization of the matrix W via PCA and color coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = net.emb.weight.data.detach()\n",
    "hatW = W[:3*sc] # extract rows corresponding to the first three concepts\n",
    "\n",
    "# Optiopnally, the word embedding goes through a LayerNorm module\n",
    "if layer_norm:\n",
    "    LN = nn.LayerNorm(d, elementwise_affine=False)\n",
    "    hatW = LN(hatW)\n",
    "\n",
    "# compute PCA of word embeddings\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "feat = pca.fit_transform(hatW.cpu())\n",
    "\n",
    "# plot the first 2 principal components\n",
    "col = ['darkblue']*sc + ['darkred']*sc + ['darkgreen']*sc\n",
    "plt.scatter(feat[:,0], feat[:,1], s=1, c=col, label='CSS color name')\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()\n",
    "\n",
    "# print first 3 singular values of the PCA\n",
    "print('First three singular values associated with the PCA:')\n",
    "print( 'sigma_1 = {:.3e} \\t sigma_2 = {:.3e} \\t sigma_3 = {:.3e}'.format( \n",
    "         pca.singular_values_[0] ,pca.singular_values_[1], pca.singular_values_[2] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D visualization of the matrix U via PCA and color coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = net.clf.weight.data.detach()\n",
    "hatU= U.view(K,L,d) # reshape U \n",
    "\n",
    "# Find all vectors u_kl such that z_kl = 0, 1 and 2 \n",
    "#(these that the vectors u_kl corresponding to concept 0, 1 and 2)\n",
    "Z = datamodel.Z\n",
    "u_kl_concept0 = hatU[Z==0]\n",
    "u_kl_concept1 = hatU[Z==1] \n",
    "u_kl_concept2 = hatU[Z==2] \n",
    "u_kl  = torch.cat( [u_kl_concept0, \n",
    "                    u_kl_concept1, \n",
    "                    u_kl_concept2] , dim=0)\n",
    "\n",
    "\n",
    "# compute the PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "feat = pca.fit_transform(u_kl.cpu())\n",
    "   \n",
    "\n",
    "# plot first 2 principal components    \n",
    "n0 = u_kl_concept0.shape[0]\n",
    "n1 = u_kl_concept1.shape[0]\n",
    "n2 = u_kl_concept2.shape[0]\n",
    "col = ['darkblue']*n0 + ['darkred']*n1+ ['darkgreen']*n2 \n",
    "plt.scatter(feat[:,0], feat[:,1], s=1, c= col, label='CSS color name')\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()\n",
    "\n",
    "# print first 3 singular values of the PCA\n",
    "print('First three singular values associated with the PCA:')\n",
    "print( 'sigma_1 = {:.3e} \\t sigma_2 = {:.3e} \\t sigma_3 = {:.3e}'.format( \n",
    "         pca.singular_values_[0] ,pca.singular_values_[1], pca.singular_values_[2] ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
